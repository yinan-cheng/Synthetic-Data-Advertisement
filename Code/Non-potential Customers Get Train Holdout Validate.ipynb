{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81af4688",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb1d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is loaded...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "path = 'Data' # Path of the dataset folder\n",
    "df_feeds = pd.read_csv(path + '/train/train_data_feeds.csv')\n",
    "df_ads = pd.read_csv(path + '/train/train_data_ads.csv')\n",
    "print(\"data is loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc8ad3",
   "metadata": {},
   "source": [
    "# 1. Find Potential Customers and Non-potential Customers\n",
    "\n",
    "- Users in the ads dataset are potential customers.\n",
    "- Users in the feeds dataset and not in the ads dataset are non-potential customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9194fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ads = df_ads['user_id'].unique()\n",
    "df_pot = df_feeds[df_feeds['u_userId'].isin(user_ads)]\n",
    "df_nonpot = df_feeds.drop(df_pot.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7694e95",
   "metadata": {},
   "source": [
    "# 2. Non-potential Customers Data Preprocess\n",
    "\n",
    "- Drop the Columns with unique value > 1000 or non-numerical value.\n",
    "- Label: Convert -1 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e584b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(751889, 28)\n",
      "(2475843, 28)\n",
      "(3227732, 28)\n"
     ]
    }
   ],
   "source": [
    "print(df_nonpot.shape)\n",
    "print(df_pot.shape)\n",
    "print(df_feeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6cad926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(751889, 28)\n",
      "u_userId                114826\n",
      "u_phonePrice                 7\n",
      "u_browserLifeCycle           8\n",
      "u_browserMode                8\n",
      "u_feedLifeCycle              8\n",
      "u_refreshTimes              10\n",
      "u_newsCatInterests       73674\n",
      "u_newsCatDislike           231\n",
      "u_newsCatInterestsST    107272\n",
      "u_click_ca2_news        151435\n",
      "i_docId                  51622\n",
      "i_s_sourceId              2552\n",
      "i_regionEntity             364\n",
      "i_cat                      207\n",
      "i_entities               49133\n",
      "i_dislikeTimes              10\n",
      "i_upTimes                   10\n",
      "i_dtype                      5\n",
      "e_ch                        19\n",
      "e_m                        262\n",
      "e_po                        27\n",
      "e_pl                      3089\n",
      "e_rn                        99\n",
      "e_section                    2\n",
      "e_et                      3561\n",
      "label                        2\n",
      "cillabel                     2\n",
      "pro                         35\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_nonpot.shape)\n",
    "print(df_nonpot.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3f3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(751889, 18)\n",
      "u_phonePrice          int64\n",
      "u_browserLifeCycle    int64\n",
      "u_browserMode         int64\n",
      "u_feedLifeCycle       int64\n",
      "u_refreshTimes        int64\n",
      "i_regionEntity        int64\n",
      "i_cat                 int64\n",
      "i_dislikeTimes        int64\n",
      "i_upTimes             int64\n",
      "i_dtype               int64\n",
      "e_ch                  int64\n",
      "e_m                   int64\n",
      "e_po                  int64\n",
      "e_rn                  int64\n",
      "e_section             int64\n",
      "label                 int64\n",
      "cillabel              int64\n",
      "pro                   int64\n",
      "dtype: object\n",
      "u_phonePrice            7\n",
      "u_browserLifeCycle      8\n",
      "u_browserMode           8\n",
      "u_feedLifeCycle         8\n",
      "u_refreshTimes         10\n",
      "i_regionEntity        364\n",
      "i_cat                 207\n",
      "i_dislikeTimes         10\n",
      "i_upTimes              10\n",
      "i_dtype                 5\n",
      "e_ch                   19\n",
      "e_m                   262\n",
      "e_po                   27\n",
      "e_rn                   99\n",
      "e_section               2\n",
      "label                   2\n",
      "cillabel                2\n",
      "pro                    35\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Importing the NumPy library, which provides support for large, multi-dimensional arrays and matrices,\n",
    "# along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\n",
    "columns_to_drop = [column for column in df_nonpot.columns if df_nonpot[column].nunique() > 1000 or df_nonpot[column].nunique() == 1]\n",
    "# Constructing a list of columns from the dataframe 'df_task' to be dropped.\n",
    "# A column is added to this list if it has more than 1000 unique values, which typically\n",
    "# suggests that the column contains highly granular data, possibly not useful for analysis\n",
    "# or could lead to issues like overfitting if used in machine learning models.\n",
    "\n",
    "df_nonpot = df_nonpot.drop(columns=columns_to_drop)\n",
    "# Removing the columns identified in the 'columns_to_drop' list from 'df_task'.\n",
    "# This operation simplifies the dataframe by excluding columns with excessive uniqueness.\n",
    "\n",
    "df_nonpot = df_nonpot.select_dtypes(include=[np.number])\n",
    "# Filtering the dataframe to include only columns that have numerical data types.\n",
    "# This step is crucial for analyses that require numerical inputs, such as mathematical\n",
    "# operations or statistical modeling.\n",
    "\n",
    "print(df_nonpot.shape)\n",
    "print(df_nonpot.dtypes)\n",
    "print(df_nonpot.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a491bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonpot['label'] = df_nonpot['label'].replace({-1:0, 1:1})\n",
    "df_nonpot['cillabel'] = df_nonpot['cillabel'].replace({-1:0, 1:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfed60",
   "metadata": {},
   "source": [
    "# 3. Get Training, Holdout and Validate dataset\n",
    "\n",
    "- The sample size of non-potential customers dataset is 750000. So, we sample a smaller dataset. The sample size of the samller one is about 50000, i.e. training + holdout + validate = 50000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7e2013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sample size is 751889, Positive Sample size is 52591, Negative Sample size is 699298, label rate is 0.0752\n",
      "Total Sample size is 19999, Positive Sample size is 1398, Negative Sample size is 18601, label rate is 0.0752\n",
      "Total Sample size is 19999, Positive Sample size is 1398, Negative Sample size is 18601, label rate is 0.0752\n",
      "Total Sample size is 9999, Positive Sample size is 699, Negative Sample size is 9300, label rate is 0.0752\n"
     ]
    }
   ],
   "source": [
    "from Dataset_Utility.utility_functions import calculate_label_rate2, get_train_holdout_validate\n",
    "calculate_label_rate2(df_nonpot, 'label')\n",
    "n = 50000 #sample size we want\n",
    "df_label_train, df_label_holdout, df_label_val = get_train_holdout_validate(df_nonpot, 'label', n)\n",
    "\n",
    "calculate_label_rate2(df_label_train,'label')\n",
    "calculate_label_rate2(df_label_holdout,'label')\n",
    "calculate_label_rate2(df_label_val,'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fdffa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "task_path = f'{path}/nonpotential_label'\n",
    "if not os.path.exists(task_path):\n",
    "    os.makedirs(task_path)\n",
    "\n",
    "df_label_train.to_csv(f'{path}/nonpotential_label/df_train.csv', index=False)\n",
    "df_label_holdout.to_csv(f'{path}/nonpotential_label/df_holdout.csv', index=False)\n",
    "df_label_val.to_csv(f'{path}/nonpotential_label/df_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8639649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sample size is 751889, Positive Sample size is 170, Negative Sample size is 751719, label rate is 0.0002\n",
      "Total Sample size is 19999, Positive Sample size is 4, Negative Sample size is 19995, label rate is 0.0002\n",
      "Total Sample size is 19999, Positive Sample size is 4, Negative Sample size is 19995, label rate is 0.0002\n",
      "Total Sample size is 9999, Positive Sample size is 2, Negative Sample size is 9997, label rate is 0.0002\n"
     ]
    }
   ],
   "source": [
    "calculate_label_rate2(df_nonpot, 'cillabel')\n",
    "n = 50000 #sample size we want\n",
    "df_cillabel_train, df_cillabel_holdout, df_cillabel_val = get_train_holdout_validate(df_nonpot, 'cillabel', n)\n",
    "\n",
    "calculate_label_rate2(df_cillabel_train,'cillabel')\n",
    "calculate_label_rate2(df_cillabel_holdout,'cillabel')\n",
    "calculate_label_rate2(df_cillabel_val,'cillabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8fd372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "task_path = f'{path}/nonpotential_cillabel'\n",
    "if not os.path.exists(task_path):\n",
    "    os.makedirs(task_path)\n",
    "\n",
    "df_cillabel_train.to_csv(f'{path}/nonpotential_cillabel/df_train.csv', index=False)\n",
    "df_cillabel_holdout.to_csv(f'{path}/nonpotential_cillabel/df_holdout.csv', index=False)\n",
    "df_cillabel_val.to_csv(f'{path}/nonpotential_cillabel/df_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c58452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
